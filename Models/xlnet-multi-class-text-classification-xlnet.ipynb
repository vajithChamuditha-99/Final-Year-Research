{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n## Data\n* The input data comprises of files within the folders with class labels as their name.\n* The textual data are emails written from one journalist to another or to their source, regarding a story.\n* Emails can be seen labelled under multiple classes which would mislead the model.\n\n# Methodology\n* To clean our data and obtain some meaningful insights, we first need to make sure our data is properly labelled and stored\n* To do so:\n    1. Read the text from each file and while doing so, make sure we are not reading duplicate data.\n    2. Load the textual data into DataFrame for easier analysis.\n    3. Clean the raw text by:\n        * Removing special characters, punctuations, pronouns, stopwords.\n        * Tokeizing each data point, i.e segmenting text into sentences and further into words.\n        * Normalize the text by converting it into lower case.\n        * Extract the lemma for each word. Ex: Lemma(swimming) -> swim.","metadata":{"_uuid":"e4f60c4b-3ac8-46f1-8ecc-4d768ddad709","_cell_guid":"0a8e4522-3010-4ba0-9dd0-bc2e01b8292f","trusted":true}},{"cell_type":"code","source":"#------------------------------------------Libraries---------------------------------------------------------------#\n####################################################################################################################\n#-------------------------------------Boiler Plate Imports---------------------------------------------------------#\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n#---------------------------------------Text Processing------------------------------------------------------------#\nimport regex\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import WordPunctTokenizer\nfrom string import punctuation\nfrom nltk.stem import WordNetLemmatizer\n#####################################################################################################################","metadata":{"_uuid":"0ce01c67-7d71-409c-94d2-ef5d9ca02ba1","_cell_guid":"fae77f62-3eb3-4b71-af02-8e6df8aece8c","execution":{"iopub.status.busy":"2021-07-03T14:35:18.210679Z","iopub.execute_input":"2021-07-03T14:35:18.210999Z","iopub.status.idle":"2021-07-03T14:35:19.622694Z","shell.execute_reply.started":"2021-07-03T14:35:18.21097Z","shell.execute_reply":"2021-07-03T14:35:19.621905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read Data from the '.txt' files","metadata":{"_uuid":"ac5293de-aaa7-4898-af1c-56e7f3eeb139","_cell_guid":"d1d51fd6-4404-4d23-905c-4bd0b7cab71b","trusted":true}},{"cell_type":"code","source":"names = []\nbase = '/kaggle/input/topic-modelling-on-emails/Data/'\nwith os.scandir(base) as entries:\n    for entry in entries:\n        if(entry.is_file() == False):\n            names.append(entry.name)\nnames","metadata":{"_uuid":"3771f283-9f4f-4d21-b39e-1a276040ce92","_cell_guid":"1e874cb6-de1b-4e13-b296-c4688b6e1774","execution":{"iopub.status.busy":"2021-07-03T14:35:19.62461Z","iopub.execute_input":"2021-07-03T14:35:19.624916Z","iopub.status.idle":"2021-07-03T14:35:19.640615Z","shell.execute_reply.started":"2021-07-03T14:35:19.624887Z","shell.execute_reply":"2021-07-03T14:35:19.639722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names.sort()","metadata":{"_uuid":"5736a9a5-cac8-4821-ad7e-9590e3596df0","_cell_guid":"3404f485-e8f3-4b38-bc89-7eb10fc008b2","execution":{"iopub.status.busy":"2021-07-03T14:35:19.642533Z","iopub.execute_input":"2021-07-03T14:35:19.643128Z","iopub.status.idle":"2021-07-03T14:35:19.64761Z","shell.execute_reply.started":"2021-07-03T14:35:19.643086Z","shell.execute_reply":"2021-07-03T14:35:19.646638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = {}\nunique = []\nfor name in names:\n    path = base + name+'/'\n    x = []\n    with os.scandir(path) as entries:\n        for entry in entries:\n            if(entry.is_file()):\n                x.append(entry.name)\n    files[name] = x\n    files[name].sort()","metadata":{"_uuid":"b4e07221-f281-45e6-853b-7dbc4af63c9c","_cell_guid":"ee15ad70-1441-4bff-acfa-26498dd8c4e9","execution":{"iopub.status.busy":"2021-07-03T14:35:19.649474Z","iopub.execute_input":"2021-07-03T14:35:19.649877Z","iopub.status.idle":"2021-07-03T14:35:23.571173Z","shell.execute_reply.started":"2021-07-03T14:35:19.649836Z","shell.execute_reply":"2021-07-03T14:35:23.570394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k, v in files.items():\n    print(k, len(v))","metadata":{"_uuid":"aeb7d0d1-947b-4f3e-bb78-8ad5e35724da","_cell_guid":"df62db09-8316-44ee-a94a-24de8bcb581c","execution":{"iopub.status.busy":"2021-07-03T14:35:23.576766Z","iopub.execute_input":"2021-07-03T14:35:23.577038Z","iopub.status.idle":"2021-07-03T14:35:23.58599Z","shell.execute_reply.started":"2021-07-03T14:35:23.577011Z","shell.execute_reply":"2021-07-03T14:35:23.585282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We now know how many files are labelled under each class. Our job now is to remove the data points that are labelled under other classes. Ex: 14147.txt is labelled under 'Crime', 'Entertainment' and 'Science', so we will be removing the entry from 'Entertainment' and 'Science'.\n* The risk here is that we might have removed the entry from a correctly labelled class. Ex: 14147.txt may be labelled as 'Science' initially and was repeated in other classes, by removing it from 'Science' we are mislabelling the data as 'Crime'.\n* But 'Science' already contains the most no. of entries, making it easier for us to train the model for that particular class. Hence, our approach doesn't affect the analysis.","metadata":{"_uuid":"291c47ca-f2e3-4abb-b9a6-cd8bc3d8d237","_cell_guid":"b87f559b-940e-41d5-af95-f7a352cd2156","trusted":true}},{"cell_type":"code","source":"names","metadata":{"_uuid":"401bb994-9473-4211-b3c3-f0a1c7c4195e","_cell_guid":"bd6dc985-9acb-4daf-b144-b561cbfe3247","execution":{"iopub.status.busy":"2021-07-03T14:35:23.590085Z","iopub.execute_input":"2021-07-03T14:35:23.590392Z","iopub.status.idle":"2021-07-03T14:35:23.597406Z","shell.execute_reply.started":"2021-07-03T14:35:23.590363Z","shell.execute_reply":"2021-07-03T14:35:23.596543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(names)):\n    x = files[names[i]]\n    for j in x:\n        for k in range(i+1, len(names)):\n            key = names[k]\n            if j in files[key]:\n                files[key].remove(j)","metadata":{"_uuid":"a6313675-2478-465f-8226-0bf7bb3672cb","_cell_guid":"d9ba6ff9-0b3e-4b0e-a6a5-5e25a93aae91","execution":{"iopub.status.busy":"2021-07-03T14:35:23.598672Z","iopub.execute_input":"2021-07-03T14:35:23.599047Z","iopub.status.idle":"2021-07-03T14:35:23.838284Z","shell.execute_reply.started":"2021-07-03T14:35:23.599012Z","shell.execute_reply":"2021-07-03T14:35:23.837668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k, v in files.items():\n    print(k, len(v))","metadata":{"_uuid":"c5f394cd-27ed-4ecd-90d9-cad0e1d98b4b","_cell_guid":"ab86b51a-7d6f-4bf4-b1cd-ece6664a859f","execution":{"iopub.status.busy":"2021-07-03T14:35:23.839767Z","iopub.execute_input":"2021-07-03T14:35:23.840106Z","iopub.status.idle":"2021-07-03T14:35:23.846477Z","shell.execute_reply.started":"2021-07-03T14:35:23.840071Z","shell.execute_reply":"2021-07-03T14:35:23.845652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* From the above result it is clearly implied that the class 'Entertainment' had no data unique to its class. \n* By not considering it, we are also eliminating any variance that can be caused by the duplicate data.","metadata":{"_uuid":"c7317ef7-419c-416b-87b4-89480a7ef6ab","_cell_guid":"c88d8371-b901-4099-a06f-2fe648e206ec","trusted":true}},{"cell_type":"code","source":"data = {}\ni = 0\n\nfor genre in files.keys() :\n    texts = files[genre]\n    for text in texts:\n        if text in files[genre]:\n            path = base + genre + '/' + text\n            with open(path, \"r\", encoding = \"latin1\") as file:\n                data[i] = file.readlines()\n                i = i+1\n            data[i-1] = [\" \".join(data[i-1]), genre] \n\ndata = pd.DataFrame(data).T\nprint(data.shape)\ndata.columns = ['Text', 'Class']\ndata.head()","metadata":{"_uuid":"34b29c2d-d890-406f-9e6a-f32cd29f5942","_cell_guid":"e460c599-9360-4636-8ba4-aa0c6eb457f1","execution":{"iopub.status.busy":"2021-07-03T14:35:23.847761Z","iopub.execute_input":"2021-07-03T14:35:23.848327Z","iopub.status.idle":"2021-07-03T14:35:35.580031Z","shell.execute_reply.started":"2021-07-03T14:35:23.84829Z","shell.execute_reply":"2021-07-03T14:35:35.579212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"_uuid":"6876f346-fced-4d1a-aa29-4aa3ec10a21d","_cell_guid":"f9374571-1581-4a28-b25b-2c2f9c0322aa","execution":{"iopub.status.busy":"2021-07-03T14:35:35.58128Z","iopub.execute_input":"2021-07-03T14:35:35.5816Z","iopub.status.idle":"2021-07-03T14:35:35.597565Z","shell.execute_reply.started":"2021-07-03T14:35:35.581571Z","shell.execute_reply":"2021-07-03T14:35:35.594177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"_uuid":"9008a463-7bf6-43f7-8a99-899a9eadd737","_cell_guid":"e3f59169-11a7-4c10-8269-7661bee6c182","execution":{"iopub.status.busy":"2021-07-03T14:35:35.599428Z","iopub.execute_input":"2021-07-03T14:35:35.599799Z","iopub.status.idle":"2021-07-03T14:35:35.60885Z","shell.execute_reply.started":"2021-07-03T14:35:35.599762Z","shell.execute_reply":"2021-07-03T14:35:35.607834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There still exists few duplicate texts which might have been the result of poor data management or sending the same mail multiple times.","metadata":{"_uuid":"62574a2a-89e1-43dd-b4b4-bd86e4b4f8cf","_cell_guid":"55309a40-98b3-4da0-90b1-4a3e08a51ca1","trusted":true}},{"cell_type":"code","source":"unique = list(data.Text.unique())\nlen(unique)","metadata":{"_uuid":"25a40f9e-cc3f-4527-bc20-eaf622bff0c5","_cell_guid":"a52c1849-fbb2-44c5-8e81-a3813f96a7d8","execution":{"iopub.status.busy":"2021-07-03T14:35:35.61064Z","iopub.execute_input":"2021-07-03T14:35:35.611123Z","iopub.status.idle":"2021-07-03T14:35:35.661909Z","shell.execute_reply.started":"2021-07-03T14:35:35.611087Z","shell.execute_reply":"2021-07-03T14:35:35.661092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic = dict(data)","metadata":{"_uuid":"9f8646a1-9379-4a0c-81e2-ce06f3aaea4b","_cell_guid":"3a8f94f3-bc91-4ebf-a17a-88d2b2de14fb","execution":{"iopub.status.busy":"2021-07-03T14:35:35.66335Z","iopub.execute_input":"2021-07-03T14:35:35.663702Z","iopub.status.idle":"2021-07-03T14:35:35.667601Z","shell.execute_reply.started":"2021-07-03T14:35:35.663667Z","shell.execute_reply":"2021-07-03T14:35:35.66671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uni = {}\ni = 0\nfor k in range(len(list(dic['Text']))):\n    if dic['Text'][k] in unique:\n        uni[i] = [dic['Text'][k], dic['Class'][k]]\n        unique.remove(dic['Text'][k])\n        i += 1","metadata":{"_uuid":"d64e42d2-6c44-45bc-9032-ad72b3366942","_cell_guid":"a60f67f6-5db8-460a-ac3a-04fa8f161388","execution":{"iopub.status.busy":"2021-07-03T14:35:35.668996Z","iopub.execute_input":"2021-07-03T14:35:35.669642Z","iopub.status.idle":"2021-07-03T14:35:35.842343Z","shell.execute_reply.started":"2021-07-03T14:35:35.669604Z","shell.execute_reply":"2021-07-03T14:35:35.84164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(uni).T\nprint(data.shape)\ndata.columns = ['Text', 'Class']\ndata.head()","metadata":{"_uuid":"0d96684f-5567-4b7a-9089-aa057f268b89","_cell_guid":"29cd8b8b-cd74-4184-b0a8-2f3a8c18f585","execution":{"iopub.status.busy":"2021-07-03T14:35:35.843737Z","iopub.execute_input":"2021-07-03T14:35:35.844082Z","iopub.status.idle":"2021-07-03T14:35:36.339936Z","shell.execute_reply.started":"2021-07-03T14:35:35.844046Z","shell.execute_reply":"2021-07-03T14:35:36.339148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax = sns.countplot(data.Class, palette = sns.color_palette(\"mako\"))","metadata":{"_uuid":"6e0f4d8e-2359-4e8f-8d35-9c145c5e26c8","_cell_guid":"966dd380-b52a-4b74-913a-2a398422f082","execution":{"iopub.status.busy":"2021-07-03T14:35:36.341568Z","iopub.execute_input":"2021-07-03T14:35:36.34191Z","iopub.status.idle":"2021-07-03T14:35:36.485058Z","shell.execute_reply.started":"2021-07-03T14:35:36.341874Z","shell.execute_reply":"2021-07-03T14:35:36.484171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_wordcloud(words,title):\n    cloud = WordCloud(width=1920, height=1080,max_font_size=200, max_words=300, background_color=\"white\").generate(words)\n    plt.figure(figsize=(20,20))\n    plt.imshow(cloud, interpolation=\"gaussian\")\n    plt.axis(\"off\") \n    plt.title(title, fontsize=60)\n    plt.show()","metadata":{"_uuid":"60e38269-a54c-45c1-85c6-90a5452d921f","_cell_guid":"e4d41931-9064-486a-8c7a-d735a6fb7116","execution":{"iopub.status.busy":"2021-07-03T14:35:36.486325Z","iopub.execute_input":"2021-07-03T14:35:36.486666Z","iopub.status.idle":"2021-07-03T14:35:36.494086Z","shell.execute_reply.started":"2021-07-03T14:35:36.486629Z","shell.execute_reply":"2021-07-03T14:35:36.493171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we managed to load our data frame, we can move to the next step, i.e cleaning the data.","metadata":{"_uuid":"d9488828-14f9-48c2-9394-509966f4ab22","_cell_guid":"8e827924-a9bc-4dac-931f-eb4f593f3f02","trusted":true}},{"cell_type":"code","source":"wordnet_lemmatizer = WordNetLemmatizer()\n\nstop = stopwords.words('english')\n\nfor punct in punctuation:\n    stop.append(punct)\n\ndef filter_text(text, stop_words):\n    word_tokens = WordPunctTokenizer().tokenize(text.lower())\n    filtered_text = [regex.sub(u'\\p{^Latin}', u'', w) for w in word_tokens if w.isalpha() and len(w) > 3]\n    filtered_text = [wordnet_lemmatizer.lemmatize(w, pos=\"v\") for w in filtered_text if not w in stop_words] \n    return \" \".join(filtered_text)","metadata":{"_uuid":"3493fa3a-4662-4153-a682-fd5d4767b6ed","_cell_guid":"2d10fd9b-4159-48b2-833b-076c5b190a1b","execution":{"iopub.status.busy":"2021-07-03T14:35:36.496091Z","iopub.execute_input":"2021-07-03T14:35:36.496873Z","iopub.status.idle":"2021-07-03T14:35:36.50906Z","shell.execute_reply.started":"2021-07-03T14:35:36.49678Z","shell.execute_reply":"2021-07-03T14:35:36.50833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"filtered_text\"] = data.Text.apply(lambda x : filter_text(x, stop)) \ndata.head()","metadata":{"_uuid":"5968d943-0013-4b87-8342-8705b69ba45e","_cell_guid":"99b31eb3-bfb7-4033-90ee-c7ccdda0f5ee","execution":{"iopub.status.busy":"2021-07-03T14:35:36.510811Z","iopub.execute_input":"2021-07-03T14:35:36.51125Z","iopub.status.idle":"2021-07-03T14:35:56.371221Z","shell.execute_reply.started":"2021-07-03T14:35:36.511198Z","shell.execute_reply":"2021-07-03T14:35:56.370537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now find some useful insights into the data set by constructing wordclouds and find term frequencies in each class.\n\n### Crime","metadata":{"_uuid":"316851e9-0ea8-471b-9c70-faa1d21bf5f1","_cell_guid":"80262bd9-635d-496b-a6ab-182c184b51ca","trusted":true}},{"cell_type":"code","source":"all_text = \" \".join(data[data.Class == \"Crime\"].filtered_text) \nmake_wordcloud(all_text, \"Crime\")","metadata":{"_uuid":"fc672fd2-f9f2-4854-95a7-158498f54a86","_cell_guid":"71ff4daf-a84b-424d-ab22-bc29a0d8080e","execution":{"iopub.status.busy":"2021-07-03T14:35:56.372436Z","iopub.execute_input":"2021-07-03T14:35:56.372771Z","iopub.status.idle":"2021-07-03T14:36:02.654535Z","shell.execute_reply.started":"2021-07-03T14:35:56.372743Z","shell.execute_reply":"2021-07-03T14:36:02.65259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top 10 words in the Crime Category","metadata":{"_uuid":"a551465e-c76d-4b84-b099-9f78251bdd9f","_cell_guid":"82a56f38-ed4c-4d39-a83b-50f4e3ef0723","trusted":true}},{"cell_type":"code","source":"count = pd.DataFrame(all_text.split(), columns = ['words'])\ntop_10 = count[count['words'].isin(list(count.words.value_counts()[:10].index[:10]))]\nplt.figure(figsize=(10,5))\nsns.barplot(x = top_10.words.value_counts().index,\n            y = top_10.words.value_counts(), palette = sns.color_palette(\"mako\"))","metadata":{"_uuid":"660909e7-8d51-41fc-b17d-dfb2e5aca6fe","_cell_guid":"0b276ec8-c0ab-4d29-a110-aa616418e58a","execution":{"iopub.status.busy":"2021-07-03T14:36:02.655631Z","iopub.execute_input":"2021-07-03T14:36:02.655934Z","iopub.status.idle":"2021-07-03T14:36:02.893588Z","shell.execute_reply.started":"2021-07-03T14:36:02.655903Z","shell.execute_reply":"2021-07-03T14:36:02.892936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Politics","metadata":{"_uuid":"1663c947-36a8-4d91-b01c-96c7a892adda","_cell_guid":"84fd311d-1f6e-4d39-afec-cddf268b5e36","trusted":true}},{"cell_type":"code","source":"all_text = \" \".join(data[data.Class == \"Politics\"].filtered_text) \nmake_wordcloud(all_text, \"Politics\")","metadata":{"_uuid":"f24efbac-a67b-44ad-871e-4986920c89dd","_cell_guid":"d4053c0c-2460-473c-b9ab-32b16f9b68b8","execution":{"iopub.status.busy":"2021-07-03T14:36:02.894937Z","iopub.execute_input":"2021-07-03T14:36:02.895323Z","iopub.status.idle":"2021-07-03T14:36:11.416827Z","shell.execute_reply.started":"2021-07-03T14:36:02.895283Z","shell.execute_reply":"2021-07-03T14:36:11.416057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top 10 words in the Politics Category","metadata":{"_uuid":"765cd0f3-51ad-40ee-837a-459482e6d1cc","_cell_guid":"f3e6daa9-c73c-48b5-836c-6f0a21cd2a3c","trusted":true}},{"cell_type":"code","source":"count = pd.DataFrame(all_text.split(), columns = ['words'])\ntop_10 = count[count['words'].isin(list(count.words.value_counts()[:10].index[:10]))]\nplt.figure(figsize=(10,5))\nsns.barplot(x = top_10.words.value_counts().index,\n            y = top_10.words.value_counts(), palette = sns.color_palette(\"mako\"))","metadata":{"_uuid":"52e074ef-162f-4130-9bf0-e3d64014427a","_cell_guid":"c83dba57-1eac-41a2-abcb-636b16080c2e","execution":{"iopub.status.busy":"2021-07-03T14:36:11.41809Z","iopub.execute_input":"2021-07-03T14:36:11.418641Z","iopub.status.idle":"2021-07-03T14:36:11.864624Z","shell.execute_reply.started":"2021-07-03T14:36:11.418597Z","shell.execute_reply":"2021-07-03T14:36:11.863655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Science","metadata":{"_uuid":"09b5c4f7-9332-4ab8-9052-d94ecd6b426c","_cell_guid":"800236d8-8c41-4467-9266-f2a6bb43a657","trusted":true}},{"cell_type":"code","source":"all_text = \" \".join(data[data.Class == \"Science\"].filtered_text) \nmake_wordcloud(all_text, \"Science\")","metadata":{"_uuid":"ac6ff16a-0241-40a7-8204-33f09267bc68","_cell_guid":"0818afbb-a43e-4d43-8e3d-0e93d489dcca","execution":{"iopub.status.busy":"2021-07-03T14:36:11.866281Z","iopub.execute_input":"2021-07-03T14:36:11.866649Z","iopub.status.idle":"2021-07-03T14:36:19.28158Z","shell.execute_reply.started":"2021-07-03T14:36:11.866612Z","shell.execute_reply":"2021-07-03T14:36:19.280752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top 10 words in the Science Category","metadata":{"_uuid":"ac89730c-8f18-47ff-9448-e0ac066c4d84","_cell_guid":"4ffe8ae3-5736-4f4e-9c5c-519be5af2d9f","trusted":true}},{"cell_type":"code","source":"count = pd.DataFrame(all_text.split(), columns = ['words'])\ntop_10 = count[count['words'].isin(list(count.words.value_counts()[:10].index[:10]))]\nplt.figure(figsize=(10,5))\nsns.barplot(x = top_10.words.value_counts().index,\n            y = top_10.words.value_counts(), palette = sns.color_palette(\"mako\"))","metadata":{"_uuid":"d8766137-59b6-4849-981b-8ef5b531baf2","_cell_guid":"72074825-fa0e-4ace-8cee-6f79c62b7e23","execution":{"iopub.status.busy":"2021-07-03T14:36:19.282883Z","iopub.execute_input":"2021-07-03T14:36:19.283381Z","iopub.status.idle":"2021-07-03T14:36:19.642644Z","shell.execute_reply.started":"2021-07-03T14:36:19.28334Z","shell.execute_reply":"2021-07-03T14:36:19.641078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:19.643978Z","iopub.execute_input":"2021-07-03T14:36:19.644343Z","iopub.status.idle":"2021-07-03T14:36:19.653869Z","shell.execute_reply.started":"2021-07-03T14:36:19.644302Z","shell.execute_reply":"2021-07-03T14:36:19.652961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Oversampling The Data","metadata":{}},{"cell_type":"code","source":"data=data.groupby('Class',as_index = False,group_keys=False).apply(lambda s: s.sample(1095,replace=True))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:19.655651Z","iopub.execute_input":"2021-07-03T14:36:19.656115Z","iopub.status.idle":"2021-07-03T14:36:19.669525Z","shell.execute_reply.started":"2021-07-03T14:36:19.656073Z","shell.execute_reply":"2021-07-03T14:36:19.668895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax = sns.countplot(data.Class, palette = sns.color_palette(\"mako\"))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:19.67091Z","iopub.execute_input":"2021-07-03T14:36:19.671279Z","iopub.status.idle":"2021-07-03T14:36:19.773478Z","shell.execute_reply.started":"2021-07-03T14:36:19.671229Z","shell.execute_reply":"2021-07-03T14:36:19.772671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XLNET","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nimport transformers\n\nimport nltk\nimport re\n\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n\nplt.style.use('seaborn')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:19.774997Z","iopub.execute_input":"2021-07-03T14:36:19.775359Z","iopub.status.idle":"2021-07-03T14:36:25.930545Z","shell.execute_reply.started":"2021-07-03T14:36:19.775322Z","shell.execute_reply":"2021-07-03T14:36:25.929664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:25.931985Z","iopub.execute_input":"2021-07-03T14:36:25.932338Z","iopub.status.idle":"2021-07-03T14:36:26.2423Z","shell.execute_reply.started":"2021-07-03T14:36:25.932308Z","shell.execute_reply":"2021-07-03T14:36:26.241554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFXLNetModel, XLNetTokenizer","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:26.244206Z","iopub.execute_input":"2021-07-03T14:36:26.244602Z","iopub.status.idle":"2021-07-03T14:36:26.250013Z","shell.execute_reply.started":"2021-07-03T14:36:26.244563Z","shell.execute_reply":"2021-07-03T14:36:26.24792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlnet_model = 'xlnet-large-cased'\nxlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:26.257409Z","iopub.execute_input":"2021-07-03T14:36:26.257663Z","iopub.status.idle":"2021-07-03T14:36:27.521827Z","shell.execute_reply.started":"2021-07-03T14:36:26.257638Z","shell.execute_reply":"2021-07-03T14:36:27.520956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_of_classes = 1 #len(names)\nnumber_of_classes","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:27.523431Z","iopub.execute_input":"2021-07-03T14:36:27.524005Z","iopub.status.idle":"2021-07-03T14:36:27.529854Z","shell.execute_reply.started":"2021-07-03T14:36:27.523965Z","shell.execute_reply":"2021-07-03T14:36:27.528995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_xlnet(mname):\n    \"\"\" Creates the model. It is composed of the XLNet main block and then\n    a classification head its added\n    \"\"\"\n    # Define token ids as inputs\n    word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32')\n\n    # Call XLNet model\n    xlnet = TFXLNetModel.from_pretrained(mname)\n    xlnet_encodings = xlnet(word_inputs)[0]\n\n    # CLASSIFICATION HEAD \n    # Collect last step from last hidden state (CLS)\n    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n    # Apply dropout for regularization\n    doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n    # Final output \n    outputs = tf.keras.layers.Dense(number_of_classes, activation='sigmoid', name='outputs')(doc_encoding)\n\n    # Compile model\n    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:27.531215Z","iopub.execute_input":"2021-07-03T14:36:27.531805Z","iopub.status.idle":"2021-07-03T14:36:27.545423Z","shell.execute_reply.started":"2021-07-03T14:36:27.531766Z","shell.execute_reply":"2021-07-03T14:36:27.544582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlnet = create_xlnet(xlnet_model)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:36:27.546716Z","iopub.execute_input":"2021-07-03T14:36:27.547067Z","iopub.status.idle":"2021-07-03T14:37:22.94827Z","shell.execute_reply.started":"2021-07-03T14:36:27.547031Z","shell.execute_reply":"2021-07-03T14:37:22.947526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlnet.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:37:22.949538Z","iopub.execute_input":"2021-07-03T14:37:22.949871Z","iopub.status.idle":"2021-07-03T14:37:22.993271Z","shell.execute_reply.started":"2021-07-03T14:37:22.949836Z","shell.execute_reply":"2021-07-03T14:37:22.992337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\ny = le.fit_transform(data['Class'])","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:37:22.994537Z","iopub.execute_input":"2021-07-03T14:37:22.99488Z","iopub.status.idle":"2021-07-03T14:37:23.000532Z","shell.execute_reply.started":"2021-07-03T14:37:22.994844Z","shell.execute_reply":"2021-07-03T14:37:22.999684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = data['filtered_text']\nlabels = data['Class']\n\n\nX_train, X_test, y_train, y_test = train_test_split(text, y, test_size=0.15, random_state=196)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:37:23.001954Z","iopub.execute_input":"2021-07-03T14:37:23.002625Z","iopub.status.idle":"2021-07-03T14:37:23.013756Z","shell.execute_reply.started":"2021-07-03T14:37:23.002585Z","shell.execute_reply":"2021-07-03T14:37:23.012928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_inputs(text, tokenizer, max_len=512):\n    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n    inps = [tokenizer.encode_plus(t, max_length=max_len, pad_to_max_length=True, add_special_tokens=True) for t in text]\n    inp_tok = np.array([a['input_ids'] for a in inps])\n    ids = np.array([a['attention_mask'] for a in inps])\n    segments = np.array([a['token_type_ids'] for a in inps])\n    return inp_tok, ids, segments","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:37:23.015842Z","iopub.execute_input":"2021-07-03T14:37:23.016122Z","iopub.status.idle":"2021-07-03T14:37:23.023702Z","shell.execute_reply.started":"2021-07-03T14:37:23.016095Z","shell.execute_reply":"2021-07-03T14:37:23.022683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def warmup(epoch, lr):\n    \"\"\"Used for increasing the learning rate slowly, this tends to achieve better convergence.\n    However, as we are finetuning for few epoch it's not crucial.\n    \"\"\"\n    return max(lr +1e-6, 2e-5)\n\ndef plot_metrics(pred, true_labels):\n    \"\"\"Plots a ROC curve with the accuracy and the AUC\"\"\"\n    acc = accuracy_score(true_labels, np.array(pred.flatten() >= .5, dtype='int'))\n    fpr, tpr, thresholds = roc_curve(true_labels, pred)\n    auc = roc_auc_score(true_labels, pred)\n\n    fig, ax = plt.subplots(1, figsize=(8,8))\n    ax.plot(fpr, tpr, color='red')\n    ax.plot([0,1], [0,1], color='black', linestyle='--')\n    ax.set_title(f\"AUC: {auc}\\nACC: {acc}\");\n    return fig","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:37:23.024997Z","iopub.execute_input":"2021-07-03T14:37:23.025365Z","iopub.status.idle":"2021-07-03T14:37:23.036008Z","shell.execute_reply.started":"2021-07-03T14:37:23.025328Z","shell.execute_reply":"2021-07-03T14:37:23.035375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp_tok, ids, segments = get_inputs(X_train, xlnet_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:37:23.037542Z","iopub.execute_input":"2021-07-03T14:37:23.038629Z","iopub.status.idle":"2021-07-03T14:37:27.184065Z","shell.execute_reply.started":"2021-07-03T14:37:23.038588Z","shell.execute_reply":"2021-07-03T14:37:27.183173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, min_delta=0.02, restore_best_weights=True),\n    tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n]","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:37:27.185402Z","iopub.execute_input":"2021-07-03T14:37:27.185737Z","iopub.status.idle":"2021-07-03T14:37:27.195314Z","shell.execute_reply.started":"2021-07-03T14:37:27.1857Z","shell.execute_reply":"2021-07-03T14:37:27.191566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = xlnet.fit(x=inp_tok, y=y_train, epochs=4, batch_size=2, validation_split=.15, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T14:37:27.196712Z","iopub.execute_input":"2021-07-03T14:37:27.197143Z","iopub.status.idle":"2021-07-03T15:49:24.78633Z","shell.execute_reply.started":"2021-07-03T14:37:27.197106Z","shell.execute_reply":"2021-07-03T15:49:24.785553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"inp_tok, ids, segments = get_inputs(X_test, xlnet_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:49:24.789914Z","iopub.execute_input":"2021-07-03T15:49:24.790196Z","iopub.status.idle":"2021-07-03T15:49:25.696528Z","shell.execute_reply.started":"2021-07-03T15:49:24.790168Z","shell.execute_reply":"2021-07-03T15:49:25.691579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = xlnet.predict(inp_tok, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:49:25.69912Z","iopub.execute_input":"2021-07-03T15:49:25.699526Z","iopub.status.idle":"2021-07-03T15:50:27.134057Z","shell.execute_reply.started":"2021-07-03T15:49:25.699487Z","shell.execute_reply":"2021-07-03T15:50:27.132719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_metrics(preds, y_test);","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:58:32.617268Z","iopub.execute_input":"2021-07-03T15:58:32.617622Z","iopub.status.idle":"2021-07-03T15:58:32.623843Z","shell.execute_reply.started":"2021-07-03T15:58:32.617586Z","shell.execute_reply":"2021-07-03T15:58:32.62301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_analysis_df = pd.DataFrame({'tweet':X_test.values, 'pred':preds.flatten(), 'real':y_test})\npred_analysis_df['rounded'] = np.array(pred_analysis_df['pred'] > 0.5, dtype='int')\ndiff = pred_analysis_df[pred_analysis_df['real'] != pred_analysis_df['rounded']]","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:58:33.742349Z","iopub.execute_input":"2021-07-03T15:58:33.742671Z","iopub.status.idle":"2021-07-03T15:58:33.767689Z","shell.execute_reply.started":"2021-07-03T15:58:33.742641Z","shell.execute_reply":"2021-07-03T15:58:33.766811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change to see other examples\nidx = 44\n\ntweet, real, pred = diff.iloc[idx, [0,2,3]]\nprint(tweet)\nprint(\"PRED: \" + str(pred))\nprint(\"REAL: \" + str(real))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T15:58:37.151617Z","iopub.execute_input":"2021-07-03T15:58:37.151946Z","iopub.status.idle":"2021-07-03T15:58:37.162378Z","shell.execute_reply.started":"2021-07-03T15:58:37.151914Z","shell.execute_reply":"2021-07-03T15:58:37.161522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tweets = dataf_test['clean']\n\n# inp_tok, ids, segments = get_inputs(tweets, xlnet_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:01:50.111979Z","iopub.execute_input":"2021-07-03T16:01:50.112325Z","iopub.status.idle":"2021-07-03T16:01:50.115748Z","shell.execute_reply.started":"2021-07-03T16:01:50.112293Z","shell.execute_reply":"2021-07-03T16:01:50.114812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = xlnet.predict(inp_tok, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:01:58.705393Z","iopub.execute_input":"2021-07-03T16:01:58.705722Z","iopub.status.idle":"2021-07-03T16:02:55.968093Z","shell.execute_reply.started":"2021-07-03T16:01:58.705692Z","shell.execute_reply":"2021-07-03T16:02:55.967429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataf_test['target'] = preds\n# dataf_test['target'] = np.array(dataf_test['target'] >= 0.5, dtype='int')\n# dataf_test[['id', 'target']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:02:55.970179Z","iopub.execute_input":"2021-07-03T16:02:55.970569Z","iopub.status.idle":"2021-07-03T16:02:55.975159Z","shell.execute_reply.started":"2021-07-03T16:02:55.97053Z","shell.execute_reply":"2021-07-03T16:02:55.974051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlnet.save_weights(\"xlnet.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:04:32.901111Z","iopub.execute_input":"2021-07-03T16:04:32.901481Z","iopub.status.idle":"2021-07-03T16:04:36.351577Z","shell.execute_reply.started":"2021-07-03T16:04:32.901451Z","shell.execute_reply":"2021-07-03T16:04:36.350454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}